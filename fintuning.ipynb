{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c630f8-f929-4386-bc48-eaebe2ccc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc742ee-1d37-42fd-bf93-7be74787e89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (0.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from tokenizers) (0.25.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\euije\\makecodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1cd61ff-e231-4c40-9ae6-c24158125b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# CUDAÍ∞Ä ÏÇ¨Ïö© Í∞ÄÎä•ÌïúÏßÄ ÌôïÏù∏\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA available: {cuda_available}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c1d7f0",
   "metadata": {
    "id": "c4c1d7f0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load Model and Tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"../summary_service/korean_paper_summary\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../summary_service/korean_paper_summary\")\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# # Î™®Îç∏Í≥º ÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä Î∂àÎü¨Ïò§Í∏∞\n",
    "# model_dir = \"lcw99/t5-base-korean-text-summary\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57cb7b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d57cb7b5",
    "outputId": "d0d873f4-49ef-4218-ca06-17b2ba3b8919"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "folder_path = \"data\"  # Ìè¥Îçî Í≤ΩÎ°ú\n",
    "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tsv')]\n",
    "\n",
    "# 2. ÌååÏùºÎì§ÏùÑ DataFrameÏúºÎ°ú ÏùΩÏñ¥ÏÑú Î≥ëÌï©\n",
    "dataframes = [pd.read_csv(file, sep='\\t') for file in all_files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41e67c6-1123-4305-8a22-4a5636b1d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news       0\n",
       "summary    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c1e987-8ff2-48b2-b370-7dfba75ede6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "merged_df = merged_df.sample(n=10000, random_state=42)\n",
    "\n",
    "train_df, test_df = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "valid_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba1ef53-1380-489d-8f83-524b8ce70f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset['news'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15641828-4746-49f4-bb22-3697d9352301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f6ac82c056428a87e055d9bd562998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euije\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094702df1047424aabb252331330adb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    # ÏûÖÎ†• ÌÖçÏä§Ìä∏ ÏÑ§Ï†ï\n",
    "    inputs = examples['news']\n",
    "    # ÏûÖÎ†• ÌÖçÏä§Ìä∏ ÌÜ†ÌÅ∞Ìôî (Ìå®Îî©, Ìä∏Î†ÅÏºÄÏù¥ÏÖò)\n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=1024, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # ÏöîÏïΩ ÌÖçÏä§Ìä∏ ÌÜ†ÌÅ∞Ìôî (Ìå®Îî©, Ìä∏Î†ÅÏºÄÏù¥ÏÖò)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples['summary'], \n",
    "            max_length=256, \n",
    "            truncation=True, \n",
    "            padding=\"max_length\", \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "    \n",
    "    # Î™®Îç∏Ïóê ÏûÖÎ†•Ìï† Îç∞Ïù¥ÌÑ∞Ïóê ÌÉÄÍ≤ü Ï∂îÍ∞Ä\n",
    "    # CUDA ÎîîÎ∞îÏù¥Ïä§Î°ú Ïù¥Îèô\n",
    "    model_inputs = {key: value.to(device) for key, value in model_inputs.items()}\n",
    "    labels = labels['input_ids'].to(device)\n",
    "    \n",
    "    # ÎîïÏÖîÎÑàÎ¶¨ ÌòïÌÉúÎ°ú Î∞òÌôò\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ ÌÜ†ÌÅ¨ÎÇòÏù¥Ïßï\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_valid = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3437ba3-1ad3-44ae-b9ed-5ef9856f4fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['news', 'summary', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 8000\n",
      "})\n",
      "[4075, 321, 222, 10853, 222, 302, 2618, 222, 10611, 222, 3561, 222, 14, 222, 664, 222, 1736, 222, 6973, 561, 834, 222, 37895, 222, 2153, 301, 222, 4268, 333, 222, 9988, 222, 2408, 222, 4577, 279, 222, 1162, 222, 12823, 311, 222, 12081, 222, 4535, 333, 222, 3092, 322, 222, 38752, 222, 11878, 333, 222, 13170, 222, 530, 15, 222, 1749, 6054, 222, 24717, 13, 222, 3595, 16879, 222, 666, 28569, 13, 222, 2112, 27889, 222, 369, 1299, 222, 5542, 1036, 274, 222, 25, 349, 222, 2258, 389, 222, 1592, 222, 388, 31664, 222, 353, 222, 2402, 477, 1219, 222, 1588, 36949, 222, 2248, 305, 222, 160, 224, 248, 1219, 302, 222, 44, 53, 7, 40, 222, 2017, 222, 1736, 222, 6973, 222, 710, 222, 4268, 302, 222, 403, 5471, 779, 222, 4681, 222, 8983, 160, 224, 249, 222, 4577, 381, 222, 1046, 322, 222, 2258, 222, 2402, 3482, 421, 222, 3653, 302, 222, 9238, 459, 333, 222, 1808, 701, 293, 222, 500, 15, 222, 433, 222, 20, 480, 311, 222, 1343, 421, 222, 9238, 459, 279, 222, 42170, 222, 353, 222, 364, 3739, 222, 2746, 222, 2402, 477, 1219, 222, 2735, 222, 450, 222, 3123, 222, 1736, 333, 222, 3747, 7075, 293, 222, 3117, 500, 15, 222, 27889, 222, 14736, 709, 222, 5542, 1036, 274, 222, 160, 224, 252, 1219, 278, 222, 2021, 305, 222, 906, 279, 222, 1162, 222, 20199, 222, 3653, 302, 222, 9238, 459, 278, 222, 2960, 428, 7591, 222, 1698, 222, 6178, 389, 222, 1343, 421, 222, 9238, 459, 278, 222, 5128, 222, 345, 222, 4463, 222, 636, 588, 160, 224, 253, 280, 222, 1214, 15, 222, 640, 222, 433, 222, 20, 480, 311, 222, 30207, 222, 4268, 222, 611, 493, 512, 42306, 222, 3574, 305, 222, 4268, 302, 222, 4075, 321, 222, 10853, 222, 4577, 279, 222, 1162, 222, 1411, 1772, 222, 3263, 291, 222, 2430, 403, 373, 222, 3561, 701, 293, 222, 500, 15, 222, 6054, 222, 24717, 222, 5542, 1036, 274, 222, 160, 224, 252, 6054, 222, 3470, 373, 222, 10611, 6550, 291, 222, 10028, 411, 222, 334, 222, 1949, 222, 804, 222, 6698, 2526, 222, 12081, 333, 222, 9975, 222, 863, 222, 10611, 222, 3263, 291, 222, 3561, 2755, 160, 224, 253, 492, 222, 160, 224, 252, 49220, 222, 1597, 222, 6528, 5377, 381, 222, 9944, 222, 4268, 222, 572, 4125, 676, 279, 222, 745, 222, 2657, 1203, 222, 1428, 2218, 715, 262, 222, 15982, 222, 1401, 222, 1251, 222, 5625, 34939, 222, 2800, 278, 222, 4135, 222, 8994, 222, 374, 222, 2179, 262, 222, 1802, 160, 224, 253, 280, 222, 1214, 15, 222, 870, 222, 160, 224, 252, 10611, 291, 222, 840, 222, 1808, 429, 222, 2724, 279, 222, 1162, 222, 3539, 34939, 222, 3561, 333, 222, 443, 222, 1021, 222, 341, 222, 21090, 222, 1435, 222, 6550, 222, 10028, 278, 222, 672, 728, 222, 3023, 222, 636, 588, 160, 224, 253, 280, 222, 1288, 15, 222, 3595, 16879, 222, 666, 28569, 222, 5542, 1036, 301, 222, 160, 224, 252, 1169, 222, 46025, 333, 222, 305, 222, 3091, 222, 678, 14191, 222, 781, 279, 222, 10611, 373, 222, 878, 222, 975, 222, 345, 222, 4018, 222, 4240, 222, 636, 588, 160, 224, 253, 492, 222, 13233, 500, 15, 222, 12823, 311, 222, 640, 222, 4268, 222, 1736, 5325, 444, 222, 2385, 36949, 222, 1736, 222, 1961, 333, 222, 8009, 305, 222, 601, 222, 9088, 401, 222, 10711, 16513, 4014, 291, 222, 4435, 222, 398, 381, 222, 1046, 322, 222, 1710, 330, 222, 37895, 291, 222, 2153, 500, 15, 222, 666, 28569, 222, 5542, 1036, 274, 222, 160, 224, 252, 4268, 222, 6528, 29740, 222, 29242, 222, 24229, 278, 222, 301, 333, 222, 20648, 15, 222, 1147, 222, 312, 4586, 222, 6183, 1485, 13, 222, 1147, 222, 1170, 333, 222, 1235, 11387, 222, 6137, 278, 222, 1147, 222, 424, 4011, 222, 8009, 6492, 222, 6708, 222, 3010, 311, 222, 1199, 222, 9931, 1485, 279, 222, 1162, 222, 9280, 1526, 333, 222, 602, 222, 1407, 638, 222, 33377, 222, 588, 160, 224, 253, 280, 222, 1214, 15, 222, 5145, 222, 160, 224, 252, 5770, 222, 1161, 311, 222, 1703, 429, 222, 1071, 278, 222, 1130, 222, 1710, 1132, 222, 1071, 267, 15, 222, 4268, 222, 2385, 456, 222, 1071, 278, 222, 812, 222, 2137, 222, 12265, 780, 4914, 222, 1075, 222, 3001, 627, 222, 1398, 222, 3001, 627, 222, 3001, 579, 222, 1182, 373, 222, 2063, 222, 7244, 222, 3001, 222, 2528, 291, 222, 8009, 411, 222, 750, 293, 222, 20625, 443, 222, 3256, 222, 869, 222, 1071, 278, 222, 2626, 160, 224, 253, 280, 222, 2453, 500, 15, 222, 5465, 343, 222, 1495, 222, 15, 222, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "1024\n",
      "[433, 20, 480, 302, 222, 5542, 1036, 274, 222, 160, 224, 248, 1219, 302, 222, 44, 53, 7, 40, 222, 2017, 222, 1736, 222, 6973, 222, 710, 222, 4268, 302, 222, 403, 5471, 779, 222, 4681, 222, 8983, 160, 224, 249, 222, 5293, 279, 222, 1162, 222, 1343, 421, 222, 9238, 459, 333, 222, 938, 701, 293, 222, 3381, 222, 3123, 1736, 333, 222, 1466, 7075, 293, 222, 2179, 291, 222, 25262, 15, 222, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_train)\n",
    "print(tokenized_train[0]['input_ids'])\n",
    "print(len(tokenized_train[0]['input_ids']))\n",
    "print(tokenized_train[0]['labels'])\n",
    "print(len(tokenized_train[0]['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89deb62-82ec-4385-b5eb-e13407910d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euije\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\euije\\AppData\\Local\\Temp\\ipykernel_41948\\199574312.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# ÌõàÎ†® ÏÑ§Ï†ï\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    evaluation_strategy=\"epoch\",  # Îß§ epochÎßàÎã§ ÌèâÍ∞Ä\n",
    "    save_strategy=\"epoch\",        # Îß§ epochÎßàÎã§ Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•\n",
    "    num_train_epochs=30,  # ÏµúÎåÄ 30 epoch\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,  # ÌõàÎ†® Ï¢ÖÎ£å ÌõÑ Í∞ÄÏû• Ï¢ãÏùÄ Î™®Îç∏ÏùÑ Î∂àÎü¨Ïò§Í∏∞\n",
    ")\n",
    "\n",
    "# Trainer ÏÑ§Ï†ï\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f8faf0-c225-4f71-ae8f-16e9c0c43952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4436' max='60000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4436/60000 13:24:39 < 168:03:29, 0.09 it/s, Epoch 2.22/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.247479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>0.242154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\accelerate\\utils\\operations.py:156\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: BatchEncoding.to() got an unexpected keyword argument 'non_blocking'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ÌååÏù∏ÌäúÎãù ÏãúÏûë\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[1;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[0;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[1;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[0;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[0;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\accelerate\\data_loader.py:561\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 561\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_non_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_state_dict()\n\u001b[0;32m    563\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\accelerate\\utils\\operations.py:158\u001b[0m, in \u001b[0;36msend_to_device\u001b[1;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39mnon_blocking)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# `torch.Tensor.to(<int num>)` is not supported by `torch_npu` (see this [issue](https://github.com/Ascend/pytorch/issues/16)).\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# This call is inside the try-block since is_npu_available is not supported by torch.compile.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_npu_available():\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:818\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor)}\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:818\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m--> 818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor)}\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    820\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ÌååÏù∏ÌäúÎãù ÏãúÏûë\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9deb940-158f-4dc7-9bd0-dcb4931f41af",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ÌèâÍ∞Ä\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:3975\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3972\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3974\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3975\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3985\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:4169\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4166\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   4168\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 4169\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4170\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4171\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4173\u001b[0m )\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:4385\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   4383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   4384\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4385\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4386\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m   4388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1642\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1638\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1639\u001b[0m             labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1640\u001b[0m         )\n\u001b[1;32m-> 1642\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1660\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1661\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m lm_logits \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\u001b[38;5;241m.\u001b[39mto(lm_logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[0;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1525\u001b[0m     )\n\u001b[0;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[0;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1313\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1308\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m encoder_attention_mask \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m encoder_attention_mask \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m cross_attn_head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;66;03m# output_attentions=True & cross_attn_head_mask can not be supported when using SDPA, and we fall back on\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;66;03m# the manual implementation that requires a 4D causal mask in all cases.\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[1;32m-> 1313\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     encoder_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(\n\u001b[0;32m   1321\u001b[0m         encoder_attention_mask, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1322\u001b[0m     )\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\modeling_attn_mask_utils.py:444\u001b[0m, in \u001b[0;36m_prepare_4d_attention_mask_for_sdpa\u001b[1;34m(mask, dtype, tgt_len)\u001b[0m\n\u001b[0;32m    441\u001b[0m is_tracing \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mProxy) \u001b[38;5;129;01mor\u001b[39;00m is_torchdynamo_compiling()\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mall(mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ÌèâÍ∞Ä\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "962b634b-3899-4262-ab9a-1d8637c8b840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./korean_summary_finetuned\\\\tokenizer_config.json',\n",
       " './korean_summary_finetuned\\\\special_tokens_map.json',\n",
       " './korean_summary_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./korean_summary_finetuned\")\n",
    "tokenizer.save_pretrained(\"./korean_summary_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0d52c8-bfc1-4567-ab82-da93cd1417ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "f1_model = AutoModelForSeq2SeqLM.from_pretrained(\"../summary_service/korean_paper_summary\")\n",
    "f1_tokenizer = AutoTokenizer.from_pretrained(\"../summary_service/korean_paper_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c2eef5-4249-4583-873b-95889f9e345d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
    "f2_model = AutoModelForSeq2SeqLM.from_pretrained(\"./korean_summary_finetuned\")\n",
    "f2_tokenizer = AutoTokenizer.from_pretrained(\"./korean_summary_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc391aa-e4ae-4aa7-83f0-9568788b0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import os\n",
    "\n",
    "folder_path = \"diff\"  # Ìè¥Îçî Í≤ΩÎ°ú\n",
    "all_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tsv')]\n",
    "\n",
    "# 2. ÌååÏùºÎì§ÏùÑ DataFrameÏúºÎ°ú ÏùΩÏñ¥ÏÑú Î≥ëÌï©\n",
    "dataframes = [pd.read_csv(file, sep='\\t') for file in all_files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "911c6290-2820-4d91-850d-af0b8d6c1816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euije\\AppData\\Local\\Temp\\ipykernel_7644\\1196624857.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f1(row[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï§ëÍµ≠Ïù∏ ÌïúÍµ≠Ïñ¥ ÌïôÏäµÏûêÏùò ÌïúÍµ≠Ïñ¥ Ïù¥Ï§ëÎ™®Ïùå ÏÇ∞Ï∂ú ÌäπÏÑ±Ïù¥ ÌïúÍµ≠Ïù∏Í≥º Îã§Î•º Í≤ÉÏù¥ÎùºÎäî Í∞ÄÏÑ§ ÌïòÏóê ÌïúÍµ≠Ïù∏Í≥º Ï§ëÍµ≠Ïù∏Ïùò ÌïúÍµ≠Ïñ¥ Ïù¥Ï§ëÎ™®ÏùåÏùò Î∞úÌôî ÏñëÏÉÅÏùÑ ÏùåÏÑ± Î∂ÑÏÑùÌïòÏó¨ ÎπÑÍµêÌïú Í≤∞Í≥º, Îëê ÏßëÎã®ÏùÄ Ï∞®Ïù¥Í∞Ä ÏóÜÎäî Í≤ÉÏúºÎ°ú ÎÇòÌÉÄÎÇ¨Í≥†, ÌôúÏùå Íµ¨Í∞ÑÏùÑ ÏãúÏûëÏßÄÏ†êÍ≥º Ï¢ÖÍ≤∞ÏßÄÏ†êÏúºÎ°ú 2Îì±Î∂ÑÏúºÎ°ú ÎÇòÎàÑÏñ¥ Ìè¨Î•¥ÎßåÌä∏Î•º Î∂ÑÏÑùÌïú Í≤∞Í≥º, Îëê ÏßëÎã®ÏùÄ Ïù¥Ï§ëÎ™®Ïùå /·Ö≠/ÏôÄ /·Ö≤/Ïùò Ï†ïÌôïÌïú Î∞úÌôîÏóê Ïñ¥Î†§ÏõÄÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏùåÏùÑ Ïïå Ïàò ÏûàÎã§.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\euije\\AppData\\Local\\Temp\\ipykernel_7644\\1196624857.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f2(row[0]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïù¥ ÎÖºÎ¨∏ÏùÄ Ï§ëÍµ≠Ïù∏ ÌïúÍµ≠Ïñ¥ ÌïôÏäµÏûêÏùò ÌïúÍµ≠Ïñ¥ Ïù¥Ï§ëÎ™®Ïùå ÏÇ∞Ï∂ú ÌäπÏÑ±Ïù¥ ÌïúÍµ≠Ïù∏Í≥º Îã§Î•º Í≤ÉÏù¥ÎùºÎäî Í∞ÄÏÑ§ ÌïòÏóê ÌïúÍµ≠Ïù∏Í≥º Ï§ëÍµ≠Ïù∏Ïùò ÌïúÍµ≠Ïñ¥ Ïù¥Ï§ëÎ™®ÏùåÏùò Î∞úÌôî ÏñëÏÉÅÏùÑ ÏùåÏÑ± Î∂ÑÏÑùÌï¥ ÎπÑÍµêÌñàÎã§. Îëê ÏßëÎã®Ïùò Ïù¥Ï§ëÎ™®Ïùå ÏÇ∞Ï∂ú Ïãú ÎÇòÌÉÄÎÇòÎäî ÏùåÌñ•ÌïôÏ†Å ÌäπÏÑ±ÏùÑ ÎπÑÍµêÌï¥ Ïñ¥Îñ†Ìïú Ï∞®Ïù¥Î•º Í∞ÄÏßÄÎäîÏßÄ ÏÇ¥Ìé¥Î≥¥ÏïòÏúºÎ©∞ ÎòêÌïú Í∑∏ Ï∞®Ïù¥Í∞Ä ÌÜµÍ≥ÑÏ†ÅÏúºÎ°ú Ïú†ÏùòÎØ∏ÌïúÍ∞ÄÏóê Í¥ÄÌï¥ ÏïåÏïÑÎ≥¥ÏïòÎã§.\n",
      "\n",
      "ÏÑúÎπÑÏä§ Î∂ÄÎ¨∏ÏùÄ Ï†úÏ°∞ÏóÖÍ≥º Îã§Î•∏ ÌäπÏÑ±ÏùÑ ÏßÄÎãàÎØÄÎ°ú Ï†ÑÌÜµÏ†ÅÏù∏ 6ÏãúÍ∑∏Îßà Ï†ÑÍ∞úÎ∞©ÏãùÏùÑ ÏÑúÎπÑÏä§ Î∂ÑÏïºÏóê Ï†ÅÏö©ÌïòÎäî Í≥ºÏ†ïÏóê Ïó¨Îü¨ Í∞ÄÏßÄ Ïñ¥Î†§ÏõÄÏù¥ Ï†úÍ∏∞ÎêòÍ≥† ÏûàÎã§. Ïù¥Ïóê Î≥∏ Ïó∞Íµ¨ÏóêÏÑúÎäî ÏÑúÎπÑÏä§ Î∂ÄÎ∂ÑÏùò ÌîÑÎ°úÏÑ∏Ïä§ Î∞è ÏÉÅÌíàÍ∞úÎ∞úÍ≥ºÏ†ïÏóê Ìö®Í≥ºÏ†ÅÏúºÎ°ú Ï†ÅÏö©Ìï† Ïàò ÏûàÎäî DFSS/S Ï≤¥Í≥ÑÏùò Ïû¨Ï†ïÎ¶Ω Î∞©ÏïàÏùÑ ÎÖºÏùòÌïòÍ≥† Í∑∏ Ï†ÅÏö© ÏÇ¨Î°ÄÎ•º ÏÜåÍ∞úÌïòÍ≥†Ïûê ÌïúÎã§.\n",
      "Î≥∏Í≥†ÏóêÏÑúÎäî ÏÑúÎπÑÏä§ Î∂ÄÎ∂ÑÏùò ÌîÑÎ°úÏÑ∏Ïä§ Î∞è ÏÉÅÌíàÍ∞úÎ∞úÍ≥ºÏ†ïÏóê Ìö®Í≥ºÏ†ÅÏúºÎ°ú Ï†ÅÏö©Ìï† Ïàò ÏûàÎäî DFSS/S Ï≤¥Í≥ÑÏùò Ïû¨Ï†ïÎ¶Ω Î∞©ÏïàÏùÑ ÎÖºÏùòÌïòÍ≥† Í∑∏ Ï†ÅÏö© ÏÇ¨Î°ÄÎ•º ÏÜåÍ∞úÌïòÍ≥†Ïûê ÌïúÎã§. DFSS/S Î°úÎìúÎßµÏùò Ï°∞Ï†ï¬∑Î≥¥ÏôÑ, Í≥†Í∞ù Î∂ÑÏÑù Î∞è CTQ(Y) ÎèÑÏ∂ú, Ïª®ÏÖâ Í∞úÎ∞úÏùÑ ÏúÑÌïú ÏïÑÏù¥ÎîîÏñ¥ ÎèÑÏ∂ú Î∞è ÌèâÍ∞Ä, Í∑∏Î¶¨Í≥† Y-y-X Ïó∞Í≥ÑÎèÑÎ•º ÌÜµÌïú Ìö®Ïú®Ï†ÅÏù∏ ÌîÑÎ°úÏÑ∏Ïä§ ÏÑ§Í≥ÑÎ∞©Ïïà Îì±Ïù¥ Í∏∞Ïà†ÎêòÎ©∞, Ïù¥Îü¨Ìïú Í∞úÎÖêÏ†Å Íµ¨Ï°∞Î•º ÏÑúÎπÑÏä§ ÏÉÅÌíàÏùò Í∞úÎ∞úÏóê Ï†ÅÏö©Ìïú Í∏∞ÏóÖ ÏÇ¨Î°ÄÎ•º Îã§Î£®Í≥† ÏûàÎã§.\n",
      "\n",
      "ÏïàÏ†ÑÌñâÏ†ïÎ∂ÄÎäî Ï†ÑÍµ≠Ïùò Ïû¨ÎÇúÏÉÅÌô©ÏùÑ 24ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅÌïòÎ©¥ÏÑú ÏÇ¨Í≥† Î∞úÏÉù Ïãú ÏúÑÍ∏∞Í¥ÄÎ¶¨Ï≤¥Í≥ÑÎ•º Ïã†ÏÜçÌûà Í∞ÄÎèôÌï¥ ÎåÄÏ≤òÌïòÎèÑÎ°ù ÌïòÎäî Î≤ïÏ†Å ÏûÑÎ¨¥Î•º Îß°Í≥† ÏûàÎã§. ÌïòÏßÄÎßå Í∞ï Ïû•Í¥ÄÏùÄ ÎåÄÌÜµÎ†πÏóêÍ≤å ÏßÄÏó∞ Î≥¥Í≥†Î•º ÌñàÎã§Îäî Ï†ê, Ï†ïÎ∂ÄÏùò Ï¥àÍ∏∞ ÎåÄÏùëÏùÑ Í∞àÌå°ÏßàÌå°ÌïòÍ≤å ÎßåÎì† Îã®Ï¥àÎ•º Ï†úÍ≥µÌñàÎã§Îäî Ï†êÎßåÏúºÎ°úÎèÑ Í∞ï Ïû•Í¥ÄÏùò Ï±ÖÏûÑÏùÄ ÌïúÏóÜÏù¥ Î¨¥Í≤ÅÎã§. Îçî ÎÜÄÎùºÏö¥ Í≤ÉÏùÄ Í∞ï Ïû•Í¥ÄÏù¥ ÏûêÏã†Ïùò Í∂åÌïúÍ≥º Ï±ÖÏûÑÏùò Î≤îÏúÑÎ•º ÌòºÎèôÌïòÍ≥† ÏûàÎã§Îäî Ï†êÏù¥Îã§. ÌïòÏßÄÎßå Ï§ëÎåÄÎ≥∏ÏùÄ ÎåÄÍ∑úÎ™® Ïû¨ÎÇúÏùò ÏòàÎ∞©¬∑ÎåÄÎπÑ¬∑ÎåÄÏùë¬∑Î≥µÍµ¨Ïóê Í¥ÄÌïú ÏÇ¨Ìï≠ÏùÑ Ï¥ùÍ¥Ñ Ï°∞Ï†ïÌïòÎäî Í∏∞Íµ¨Îã§. 24ÏãúÍ∞Ñ Ï†ïÌôïÌïú ÏÉÅÌô©ÏùÑ ÌååÏïÖÌï¥ Ï†ÑÌååÌïòÍ≥† Î∂ÄÏ≤òÎ≥Ñ Ïó≠Ìï†ÏùÑ Î∂ÑÎã¥¬∑Ï°∞Ï†ïÌï¥ Ìï©Îèô ÏßÄÏõêÏ±ÖÏùÑ ÎßàÎ†®Ìï¥Ïïº Ìï† Ï±ÖÏûÑÏù¥ ÏûàÎã§.\n",
      "ÏÑ∏ÏõîÌò∏ Ï∞∏ÏÇ¨Ïùò Ï±ÖÏûÑÏÜåÏû¨Î•º ÎÜìÍ≥† Îî∞ÏßÄÏûêÎ©¥ ÏÑ†Ïû•¬∑ÏÑ†ÏõêÍ≥º ÏÑ†ÏÇ¨(ËàπÁ§æ), Í∑∏Î¶¨Í≥† Ìï¥Í≤ΩÏùÑ Ïö∞ÏÑ† ÍºΩÏïÑÏïºÍ≤†ÏßÄÎßå ÏïàÏ†ÑÌñâÏ†ïÎ∂ÄÎäî Ï†ÑÍµ≠Ïùò Ïû¨ÎÇúÏÉÅÌô©ÏùÑ 24ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅÌïòÎ©¥ÏÑú ÏÇ¨Í≥† Î∞úÏÉù Ïãú ÏúÑÍ∏∞Í¥ÄÎ¶¨Ï≤¥Í≥ÑÎ•º Ïã†ÏÜçÌûà Í∞ÄÎèôÌï¥ ÎåÄÏ≤òÌïòÎèÑÎ°ù ÌïòÎäî Î≤ïÏ†Å ÏûÑÎ¨¥Î•º Îß°Í≥† ÏûàÎã§Îäî Ï†êÏóêÏÑú Ï±ÖÏûÑÏù¥ ÎßâÏ§ëÌïúÎç∞ Í∞ïÌñâÎ∂ÄÏôÄ Í∞ïÎ≥ëÍ∑ú ÏïàÌñâÎ∂Ä Ïû•Í¥ÄÏùÄ Í∑∏ Í∞ôÏùÄ ÏûÑÎ¨¥Î•º ÏàòÌñâÌï† Îä•Î†•Í≥º ÏùòÏßÄ, Ï±ÖÏûÑÍ∞êÏù¥ ÏóÜÎäî Í≤É Í∞ôÎã§.\n",
      "\n",
      "ÎπÖÎç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ ÎπàÎèÑ ÏïÑÏù¥ÌÖú ÏßëÌï©Îì§ÏùÑ ÎßàÏù¥ÎãùÌïòÍ∏∞ ÏúÑÌï¥ Î©îÎ™®Î¶¨ÏôÄ ÎîîÏä§ÌÅ¨Î•º Ìï®Íªò ÏÇ¨Ïö©ÌïòÎäî Ïä§ÌÉù Í∏∞Î∞òÏùò ÏÉàÎ°úÏö¥ Ï†ëÍ∑ºÎ≤ïÏù∏ PPFP ÏïåÍ≥†Î¶¨Ï¶òÏùÑ Ï†úÏïàÌïòÏòÄÎã§. PPFPÎäî ÎπàÎ∞ú Ìå®ÌÑ¥ ÎßàÏù¥Îãù Ï†ëÍ∑ºÎ≤ï Ï§ë Í∞ÄÏû• Ïù∏Í∏∞ ÏûàÍ≥† Ìö®Ïú®Ï†ÅÏù∏ Ï†ëÍ∑ºÎ≤ï Ï§ë ÌïòÎÇòÏù∏ FP-growthÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÍ≥† ÏûàÎã§.\n",
      "Î≥∏Í≥†ÏóêÏÑúÎäî ÎπÖÎç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ ÎπàÎèÑ ÏïÑÏù¥ÌÖú ÏßëÌï©Îì§ÏùÑ ÎßàÏù¥ÎãùÌïòÍ∏∞ ÏúÑÌï¥ Î©îÎ™®Î¶¨ÏôÄ ÎîîÏä§ÌÅ¨Î•º Ìï®Íªò ÏÇ¨Ïö©ÌïòÎäî Ïä§ÌÉù Í∏∞Î∞òÏùò ÏÉàÎ°úÏö¥ Ï†ëÍ∑ºÎ≤ïÏù∏ PPFP ÏïåÍ≥†Î¶¨Ï¶òÏùÑ Ï†úÏïàÌñàÎã§. PPFPÎäî ÎπàÎ∞ú Ìå®ÌÑ¥ ÎßàÏù¥Îãù Ï†ëÍ∑ºÎ≤ï Ï§ë Í∞ÄÏû• Ïù∏Í∏∞ ÏûàÍ≥† Ìö®Ïú®Ï†ÅÏù∏ Ï†ëÍ∑ºÎ≤ï Ï§ë ÌïòÎÇòÏù∏ FP-growthÎ•º Í∏∞Î∞òÏúºÎ°ú ÌïòÍ≥† ÏûàÎã§.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m merged_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mf1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f2(row[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mf1\u001b[1;34m(report)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1\u001b[39m(report):\n\u001b[0;32m      2\u001b[0m     inputs1 \u001b[38;5;241m=\u001b[39m f1_tokenizer(report, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m     summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mf1_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m350\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f1_tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:2246\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2239\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2240\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2241\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2242\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2243\u001b[0m     )\n\u001b[0;32m   2245\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2246\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2247\u001b[0m         input_ids,\n\u001b[0;32m   2248\u001b[0m         beam_scorer,\n\u001b[0;32m   2249\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2250\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2251\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2252\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2253\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2254\u001b[0m     )\n\u001b[0;32m   2256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2258\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2259\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2260\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2267\u001b[0m     )\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:3547\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3544\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[0;32m   3546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3547\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[0;32m   3549\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[0;32m   3552\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:3321\u001b[0m, in \u001b[0;36mGenerationMixin._temporary_reorder_cache\u001b[1;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[0;32m   3318\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past_key_values)\n\u001b[0;32m   3319\u001b[0m \u001b[38;5;66;03m# Standard code path: use the `Cache.reorder_cache`\u001b[39;00m\n\u001b[0;32m   3320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3321\u001b[0m     \u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m past_key_values\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\cache_utils.py:1498\u001b[0m, in \u001b[0;36mEncoderDecoderCache.reorder_cache\u001b[1;34m(self, beam_idx)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attention_cache\u001b[38;5;241m.\u001b[39mreorder_cache(beam_idx)\n\u001b[1;32m-> 1498\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_attention_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\MakeCodes\\learn\\softare_engineearing\\summary_service\\venv\\lib\\site-packages\\transformers\\cache_utils.py:101\u001b[0m, in \u001b[0;36mCache.reorder_cache\u001b[1;34m(self, beam_idx)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m!=\u001b[39m []:\n\u001b[0;32m    100\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, \u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    print(f1(row[0]))\n",
    "    print(f2(row[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4827680f-71c2-4029-a65a-109adde8598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f1(report):\n",
    "    inputs1 = f1_tokenizer(report, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = f1_model.generate(inputs1[\"input_ids\"], num_beams=4, max_length=350)\n",
    "    return f1_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7b94e9-db1a-4752-a7c7-159f2933d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(report):\n",
    "    inputs2 = f2_tokenizer(report, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = f2_model.generate(inputs2[\"input_ids\"], num_beams=4, max_length=350)\n",
    "    return f2_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "610dd86d-53b3-404c-8f47-3a2e8dca9d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏïàÏ†ÑÌñâÏ†ïÎ∂ÄÎäî Ï†ÑÍµ≠Ïùò Ïû¨ÎÇúÏÉÅÌô©ÏùÑ 24ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅÌïòÎ©¥ÏÑú ÏÇ¨Í≥† Î∞úÏÉù Ïãú ÏúÑÍ∏∞Í¥ÄÎ¶¨Ï≤¥Í≥ÑÎ•º Ïã†ÏÜçÌûà Í∞ÄÎèôÌï¥ ÎåÄÏ≤òÌïòÎèÑÎ°ù ÌïòÎäî Î≤ïÏ†Å ÏûÑÎ¨¥Î•º Îß°Í≥† ÏûàÎã§.\n"
     ]
    }
   ],
   "source": [
    "report = \"ÏïàÏ†ÑÌñâÏ†ïÎ∂ÄÎäî Ï†ÑÍµ≠Ïùò Ïû¨ÎÇúÏÉÅÌô©ÏùÑ 24ÏãúÍ∞Ñ Î™®ÎãàÌÑ∞ÎßÅÌïòÎ©¥ÏÑú ÏÇ¨Í≥† Î∞úÏÉù Ïãú ÏúÑÍ∏∞Í¥ÄÎ¶¨Ï≤¥Í≥ÑÎ•º Ïã†ÏÜçÌûà Í∞ÄÎèôÌï¥ ÎåÄÏ≤òÌïòÎèÑÎ°ù ÌïòÎäî Î≤ïÏ†Å ÏûÑÎ¨¥Î•º Îß°Í≥† ÏûàÎã§. ÌïòÏßÄÎßå Í∞ï Ïû•Í¥ÄÏùÄ ÎåÄÌÜµÎ†πÏóêÍ≤å ÏßÄÏó∞ Î≥¥Í≥†Î•º ÌñàÎã§Îäî Ï†ê, Ï†ïÎ∂ÄÏùò Ï¥àÍ∏∞ ÎåÄÏùëÏùÑ Í∞àÌå°ÏßàÌå°ÌïòÍ≤å ÎßåÎì† Îã®Ï¥àÎ•º Ï†úÍ≥µÌñàÎã§Îäî Ï†êÎßåÏúºÎ°úÎèÑ Í∞ï Ïû•Í¥ÄÏùò Ï±ÖÏûÑÏùÄ ÌïúÏóÜÏù¥ Î¨¥Í≤ÅÎã§. Îçî ÎÜÄÎùºÏö¥ Í≤ÉÏùÄ Í∞ï Ïû•Í¥ÄÏù¥ ÏûêÏã†Ïùò Í∂åÌïúÍ≥º Ï±ÖÏûÑÏùò Î≤îÏúÑÎ•º ÌòºÎèôÌïòÍ≥† ÏûàÎã§Îäî Ï†êÏù¥Îã§. ÌïòÏßÄÎßå Ï§ëÎåÄÎ≥∏ÏùÄ ÎåÄÍ∑úÎ™® Ïû¨ÎÇúÏùò ÏòàÎ∞©¬∑ÎåÄÎπÑ¬∑ÎåÄÏùë¬∑Î≥µÍµ¨Ïóê Í¥ÄÌïú ÏÇ¨Ìï≠ÏùÑ Ï¥ùÍ¥Ñ Ï°∞Ï†ïÌïòÎäî Í∏∞Íµ¨Îã§. 24ÏãúÍ∞Ñ Ï†ïÌôïÌïú ÏÉÅÌô©ÏùÑ ÌååÏïÖÌï¥ Ï†ÑÌååÌïòÍ≥† Î∂ÄÏ≤òÎ≥Ñ Ïó≠Ìï†ÏùÑ Î∂ÑÎã¥¬∑Ï°∞Ï†ïÌï¥ Ìï©Îèô ÏßÄÏõêÏ±ÖÏùÑ ÎßàÎ†®Ìï¥Ïïº Ìï† Ï±ÖÏûÑÏù¥ ÏûàÎã§.\"\n",
    "\n",
    "inputs = tokenizer(report, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=350)\n",
    "result = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd11aca-5640-44c1-8bb0-01a0b7d9c349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be93b6-a70a-4143-bf3a-ba7358555eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03c8a7123fcf415e912dd51fc74c3f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0466cfc0634a41cc9534a30cc983ae92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "174505f02d9841c9b673e2f8c5ddf8dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a05627d898e4c79b0e7cb8455991a94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0a9c8f47a104464ba67f3f269ddb26d",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7073aec6a284fc98366b8f15f2b921f",
      "value": 9912422
     }
    },
    "2015dbfc8a64487da6e9ca92ad5d1934": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b152f2925dd41ecb49e209c4a3549e4",
      "max": 28881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac61edb7ec464ec28b2f28396affc65f",
      "value": 28881
     }
    },
    "223b0f005cfb479d81d9f359083b19df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5b4247f4825450c9ccb9491fc259972",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0466cfc0634a41cc9534a30cc983ae92",
      "value": " 4542/4542 [00:00&lt;00:00, 165920.80it/s]"
     }
    },
    "26d5920f7de34d748c04629e0a3856c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3da2b474fe1d4a51a6d03f14f6a10d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9082479d39c04a6198ef36979ce5aae2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_03c8a7123fcf415e912dd51fc74c3f6e",
      "value": "100%"
     }
    },
    "454973193f784c33ae361ea2c8a2f7ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "487b044f3f804203ad1402b6ddadb7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ac08e6ea515410c8cc0714182361a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_487b044f3f804203ad1402b6ddadb7ab",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_852cabde0e4c4345aba1498f850aad0a",
      "value": " 28881/28881 [00:00&lt;00:00, 752353.56it/s]"
     }
    },
    "4e9c2a745c98409a9e2f9a97579522e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "533fc05768e147ef9798b80b19ccb521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0b53ce1025347159b2dc60f9381edb8",
      "max": 4542,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4e9c2a745c98409a9e2f9a97579522e5",
      "value": 4542
     }
    },
    "59f48db215c74b90a16c4e6d320fceea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "631479347b0c4c7a990805575eeb90d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59f48db215c74b90a16c4e6d320fceea",
      "max": 1648877,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2bc6c33c3cf4dc68f3826463746ee31",
      "value": 1648877
     }
    },
    "64708b716613459c9ace31def8972515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "678c84bbdf8e44e6b64f59ec98f6d6a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68a649f839264d299aa635f77232b97e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7725714caae54deea6fd0bc1c2484c83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd5ba4e33c6e4ee49284c7ede2635a7a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e8cd191495044ca58f15680d9c251ce2",
      "value": "100%"
     }
    },
    "7864206061494aef93f605f2d4880f48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fad5275259c84a428de9e429194ccb28",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_68a649f839264d299aa635f77232b97e",
      "value": "100%"
     }
    },
    "7acea8b0e33d4726b9da41243eb37324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_866a73417db542b68ba6531a1a78e47b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_26d5920f7de34d748c04629e0a3856c0",
      "value": "100%"
     }
    },
    "7c0ba11516814dbca46b286fc27b91de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3da2b474fe1d4a51a6d03f14f6a10d05",
       "IPY_MODEL_533fc05768e147ef9798b80b19ccb521",
       "IPY_MODEL_223b0f005cfb479d81d9f359083b19df"
      ],
      "layout": "IPY_MODEL_ec28df9e87654ee19d2a42359b0b9139"
     }
    },
    "852cabde0e4c4345aba1498f850aad0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "866a73417db542b68ba6531a1a78e47b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9082479d39c04a6198ef36979ce5aae2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b152f2925dd41ecb49e209c4a3549e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0b53ce1025347159b2dc60f9381edb8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2bc6c33c3cf4dc68f3826463746ee31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a56f504703a34fabbfb627685070b1b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_678c84bbdf8e44e6b64f59ec98f6d6a0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d26f587a1d604f16b5d56d54df445c1b",
      "value": " 1648877/1648877 [00:00&lt;00:00, 11645981.88it/s]"
     }
    },
    "a7073aec6a284fc98366b8f15f2b921f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "abb64f413e494ccbb083030db4c2dd97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7acea8b0e33d4726b9da41243eb37324",
       "IPY_MODEL_631479347b0c4c7a990805575eeb90d9",
       "IPY_MODEL_a56f504703a34fabbfb627685070b1b3"
      ],
      "layout": "IPY_MODEL_c314355fe46e4ad7b8eb909d13afda10"
     }
    },
    "ac61edb7ec464ec28b2f28396affc65f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5b4247f4825450c9ccb9491fc259972": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b65c23aba7c8416f884ba3156b91bedf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7725714caae54deea6fd0bc1c2484c83",
       "IPY_MODEL_1a05627d898e4c79b0e7cb8455991a94",
       "IPY_MODEL_d893ff44bc2649569aec5db611925541"
      ],
      "layout": "IPY_MODEL_454973193f784c33ae361ea2c8a2f7ca"
     }
    },
    "c314355fe46e4ad7b8eb909d13afda10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d26f587a1d604f16b5d56d54df445c1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d893ff44bc2649569aec5db611925541": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_174505f02d9841c9b673e2f8c5ddf8dd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_64708b716613459c9ace31def8972515",
      "value": " 9912422/9912422 [00:00&lt;00:00, 5134186.12it/s]"
     }
    },
    "dd5ba4e33c6e4ee49284c7ede2635a7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e291b037a1db44ebaa8cff0cb25e5dd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8cd191495044ca58f15680d9c251ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec28df9e87654ee19d2a42359b0b9139": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0a9c8f47a104464ba67f3f269ddb26d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fad5275259c84a428de9e429194ccb28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd4e360d84324e5097cd858956ee1d67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7864206061494aef93f605f2d4880f48",
       "IPY_MODEL_2015dbfc8a64487da6e9ca92ad5d1934",
       "IPY_MODEL_4ac08e6ea515410c8cc0714182361a79"
      ],
      "layout": "IPY_MODEL_e291b037a1db44ebaa8cff0cb25e5dd0"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
